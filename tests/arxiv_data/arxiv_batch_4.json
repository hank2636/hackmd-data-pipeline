[
  {
    "entry_id": "http://arxiv.org/abs/2510.11498v1",
    "title": "ReLook: Vision-Grounded RL with a Multimodal LLM Critic for Agentic Web Coding",
    "authors": [
      "Yuhang Li",
      "Chenchen Zhang",
      "Ruilin Lv",
      "Ao Liu",
      "Ken Deng",
      "Yuanxing Zhang",
      "Jiaheng Liu",
      "Wiggin Zhou",
      "Bo Zhou"
    ],
    "summary": "While Large Language Models (LLMs) excel at algorithmic code generation, they\nstruggle with front-end development, where correctness is judged on rendered\npixels and interaction. We present ReLook, an agentic, vision-grounded\nreinforcement learning framework that empowers an agent to close a robust\ngenerate--diagnose--refine loop by invoking a multimodal LLM (MLLM) as a tool.\nDuring training, the agent uses the MLLM-in-the-loop both as a visual\ncritic--scoring code with screenshots--and as a source of actionable,\nvision-grounded feedback; a strict zero-reward rule for invalid renders anchors\nrenderability and prevents reward hacking. To prevent behavioral collapse, we\nintroduce Forced Optimization, a strict acceptance rule that admits only\nimproving revisions, yielding monotonically better trajectories. At inference,\nwe decouple the critic and run a lightweight, critic-free self-edit cycle,\nkeeping latency comparable to base decoding while retaining most of the gains.\nAcross three widely used benchmarks, ReLook consistently outperforms strong\nbaselines in vision-grounded front-end code generation, highlighting the\nbenefits of agentic perception, visual rewards, and training-inference\ndecoupling.",
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "published": "2025-10-13T15:05:50+00:00",
    "updated": "2025-10-13T15:05:50+00:00",
    "journal_ref": null,
    "doi": null
  },
  {
    "entry_id": "http://arxiv.org/abs/2510.11495v1",
    "title": "How Reinforcement Learning After Next-Token Prediction Facilitates Learning",
    "authors": [
      "Nikolaos Tsilivis",
      "Eran Malach",
      "Karen Ullrich",
      "Julia Kempe"
    ],
    "summary": "Recent advances in reasoning domains with neural networks have primarily been\nenabled by a training recipe that optimizes Large Language Models, previously\ntrained to predict the next-token in a sequence, with reinforcement learning\nalgorithms. We introduce a framework to study the success of this paradigm, and\nwe theoretically expose the optimization mechanisms by which reinforcement\nlearning improves over next-token prediction in this setting. We study learning\nfrom mixture distributions of short and long ``chain-of-thought'' sequences\nencoding a single task. In particular, when the task consists of predicting the\nparity of $d$ bits and long sequences are rare, we show how reinforcement\nlearning after next-token prediction enables autoregressive transformers to\ngeneralize, whereas mere next-token prediction requires extreme statistical or\ncomputational resources to do so. We further explain how reinforcement learning\nleverages increased test-time computation, manifested in longer responses, to\nfacilitate this learning process. In a simplified setting, we theoretically\nprove that autoregressive linear models following this training recipe can\nefficiently learn to predict the parity of $d$ bits as long as the proportion\nof long demonstrations in the data mix is not exponentially small in the input\ndimension $d$. Finally, we demonstrate these same phenomena in other settings,\nincluding the post-training of Llama-series models on mixture variations of\ncommon mathematical reasoning benchmarks.",
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-13T15:04:00+00:00",
    "updated": "2025-10-13T15:04:00+00:00",
    "journal_ref": null,
    "doi": null
  },
  {
    "entry_id": "http://arxiv.org/abs/2510.11491v1",
    "title": "Constraint-Aware Reinforcement Learning via Adaptive Action Scaling",
    "authors": [
      "Murad Dawood",
      "Usama Ahmed Siddiquie",
      "Shahram Khorshidi",
      "Maren Bennewitz"
    ],
    "summary": "Safe reinforcement learning (RL) seeks to mitigate unsafe behaviors that\narise from exploration during training by reducing constraint violations while\nmaintaining task performance. Existing approaches typically rely on a single\npolicy to jointly optimize reward and safety, which can cause instability due\nto conflicting objectives, or they use external safety filters that override\nactions and require prior system knowledge. In this paper, we propose a modular\ncost-aware regulator that scales the agent's actions based on predicted\nconstraint violations, preserving exploration through smooth action modulation\nrather than overriding the policy. The regulator is trained to minimize\nconstraint violations while avoiding degenerate suppression of actions. Our\napproach integrates seamlessly with off-policy RL methods such as SAC and TD3,\nand achieves state-of-the-art return-to-cost ratios on Safety Gym locomotion\ntasks with sparse costs, reducing constraint violations by up to 126 times\nwhile increasing returns by over an order of magnitude compared to prior\nmethods.",
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "published": "2025-10-13T14:59:28+00:00",
    "updated": "2025-10-13T14:59:28+00:00",
    "journal_ref": null,
    "doi": null
  },
  {
    "entry_id": "http://arxiv.org/abs/2510.11484v1",
    "title": "Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware",
    "authors": [
      "Lion Mueller",
      "Alberto Garcia-Ortiz",
      "Ardalan Najafi",
      "Adam Fuks",
      "Lennart Bamberg"
    ],
    "summary": "Integer AI inference significantly reduces computational complexity in\nembedded systems. Quantization-aware training (QAT) helps mitigate accuracy\ndegradation associated with post-training quantization but still overlooks the\nimpact of integer rescaling during inference, which is a hardware costly\noperation in integer-only AI inference. This work shows that rescaling cost can\nbe dramatically reduced post-training, by applying a stronger quantization to\nthe rescale multiplicands at no model-quality loss. Furthermore, we introduce\nRescale-Aware Training, a fine tuning method for ultra-low bit-width rescaling\nmultiplicands. Experiments show that even with 8x reduced rescaler widths, the\nfull accuracy is preserved through minimal incremental retraining. This enables\nmore energy-efficient and cost-efficient AI inference for resource-constrained\nembedded systems.",
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AR"
    ],
    "published": "2025-10-13T14:55:34+00:00",
    "updated": "2025-10-13T14:55:34+00:00",
    "journal_ref": null,
    "doi": null
  },
  {
    "entry_id": "http://arxiv.org/abs/2510.11474v1",
    "title": "Coordinated Strategies in Realistic Air Combat by Hierarchical Multi-Agent Reinforcement Learning",
    "authors": [
      "Ardian Selmonaj",
      "Giacomo Del Rio",
      "Adrian Schneider",
      "Alessandro Antonucci"
    ],
    "summary": "Achieving mission objectives in a realistic simulation of aerial combat is\nhighly challenging due to imperfect situational awareness and nonlinear flight\ndynamics. In this work, we introduce a novel 3D multi-agent air combat\nenvironment and a Hierarchical Multi-Agent Reinforcement Learning framework to\ntackle these challenges. Our approach combines heterogeneous agent dynamics,\ncurriculum learning, league-play, and a newly adapted training algorithm. To\nthis end, the decision-making process is organized into two abstraction levels:\nlow-level policies learn precise control maneuvers, while high-level policies\nissue tactical commands based on mission objectives. Empirical results show\nthat our hierarchical approach improves both learning efficiency and combat\nperformance in complex dogfight scenarios.",
    "primary_category": "cs.RO",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.MA"
    ],
    "published": "2025-10-13T14:44:51+00:00",
    "updated": "2025-10-13T14:44:51+00:00",
    "journal_ref": null,
    "doi": null
  },
  {
    "entry_id": "http://arxiv.org/abs/2510.11472v1",
    "title": "Differentiable Fast Top-K Selection for Large-Scale Recommendation",
    "authors": [
      "Yanjie Zhu",
      "Zhen Zhang",
      "Yunli Wang",
      "Zhiqiang Wang",
      "Yu Li",
      "Rufan Zhou",
      "Shiyang Wen",
      "Peng Jiang",
      "Chenhao Lin",
      "Jian Yang"
    ],
    "summary": "Cascade ranking is a widely adopted paradigm in large-scale information\nretrieval systems for Top-K item selection. However, the Top-K operator is\nnon-differentiable, hindering end-to-end training. Existing methods include\nLearning-to-Rank approaches (e.g., LambdaLoss), which optimize ranking metrics\nlike NDCG and suffer from objective misalignment, and differentiable\nsorting-based methods (e.g., ARF, LCRON), which relax permutation matrices for\ndirect Top-K optimization but introduce gradient conflicts through matrix\naggregation. A promising alternative is to directly construct a differentiable\napproximation of the Top-K selection operator, bypassing the use of soft\npermutation matrices. However, even state-of-the-art differentiable Top-K\noperator (e.g., LapSum) require $O(n \\log n)$ complexity due to their\ndependence on sorting for solving the threshold. Thus, we propose DFTopK, a\nnovel differentiable Top-K operator achieving optimal $O(n)$ time complexity.\nBy relaxing normalization constraints, DFTopK admits a closed-form solution and\navoids sorting. DFTopK also avoids the gradient conflicts inherent in\ndifferentiable sorting-based methods. We evaluate DFTopK on both the public\nbenchmark RecFLow and an industrial system. Experimental results show that\nDFTopK significantly improves training efficiency while achieving superior\nperformance, which enables us to scale up training samples more efficiently. In\nthe online A/B test, DFTopK yielded a +1.77\\% revenue lift with the same\ncomputational budget compared to the baseline. To the best of our knowledge,\nthis work is the first to introduce differentiable Top-K operators into\nrecommendation systems and the first to achieve theoretically optimal\nlinear-time complexity for Top-K selection. We have open-sourced our\nimplementation to facilitate future research in both academia and industry.",
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-13T14:40:49+00:00",
    "updated": "2025-10-13T14:40:49+00:00",
    "journal_ref": null,
    "doi": null
  },
  {
    "entry_id": "http://arxiv.org/abs/2510.11471v1",
    "title": "Iterative Amortized Inference: Unifying In-Context Learning and Learned Optimizers",
    "authors": [
      "Sarthak Mittal",
      "Divyat Mahajan",
      "Guillaume Lajoie",
      "Mohammad Pezeshki"
    ],
    "summary": "Modern learning systems increasingly rely on amortized learning - the idea of\nreusing computation or inductive biases shared across tasks to enable rapid\ngeneralization to novel problems. This principle spans a range of approaches,\nincluding meta-learning, in-context learning, prompt tuning, learned optimizers\nand more. While motivated by similar goals, these approaches differ in how they\nencode and leverage task-specific information, often provided as in-context\nexamples. In this work, we propose a unified framework which describes how such\nmethods differ primarily in the aspects of learning they amortize - such as\ninitializations, learned updates, or predictive mappings - and how they\nincorporate task data at inference. We introduce a taxonomy that categorizes\namortized models into parametric, implicit, and explicit regimes, based on\nwhether task adaptation is externalized, internalized, or jointly modeled.\nBuilding on this view, we identify a key limitation in current approaches: most\nmethods struggle to scale to large datasets because their capacity to process\ntask data at inference (e.g., context length) is often limited. To address\nthis, we propose iterative amortized inference, a class of models that refine\nsolutions step-by-step over mini-batches, drawing inspiration from stochastic\noptimization. Our formulation bridges optimization-based meta-learning with\nforward-pass amortization in models like LLMs, offering a scalable and\nextensible foundation for general-purpose task adaptation.",
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-13T14:40:47+00:00",
    "updated": "2025-10-13T14:40:47+00:00",
    "journal_ref": null,
    "doi": null
  },
  {
    "entry_id": "http://arxiv.org/abs/2510.11442v1",
    "title": "Reconstructing 12-Lead ECG from 3-Lead ECG using Variational Autoencoder to Improve Cardiac Disease Detection of Wearable ECG Devices",
    "authors": [
      "Xinyan Guan",
      "Yongfan Lai",
      "Jiarui Jin",
      "Jun Li",
      "Haoyu Wang",
      "Qinghao Zhao",
      "Deyun Zhang",
      "Shijia Geng",
      "Shenda Hong"
    ],
    "summary": "Twelve-lead electrocardiograms (ECGs) are the clinical gold standard for\ncardiac diagnosis, providing comprehensive spatial coverage of the heart\nnecessary to detect conditions such as myocardial infarction (MI). However,\ntheir lack of portability limits continuous and large-scale use. Three-lead ECG\nsystems are widely used in wearable devices due to their simplicity and\nmobility, but they often fail to capture pathologies in unmeasured regions. To\naddress this, we propose WearECG, a Variational Autoencoder (VAE) method that\nreconstructs twelve-lead ECGs from three leads: II, V1, and V5. Our model\nincludes architectural improvements to better capture temporal and spatial\ndependencies in ECG signals. We evaluate generation quality using MSE, MAE, and\nFrechet Inception Distance (FID), and assess clinical validity via a Turing\ntest with expert cardiologists. To further validate diagnostic utility, we\nfine-tune ECGFounder, a large-scale pretrained ECG model, on a multi-label\nclassification task involving over 40 cardiac conditions, including six\ndifferent myocardial infarction locations, using both real and generated\nsignals. Experiments on the MIMIC dataset show that our method produces\nphysiologically realistic and diagnostically informative signals, with robust\nperformance in downstream tasks. This work demonstrates the potential of\ngenerative modeling for ECG reconstruction and its implications for scalable,\nlow-cost cardiac screening.",
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T05",
      "I.2.6; I.2.7"
    ],
    "published": "2025-10-13T14:14:37+00:00",
    "updated": "2025-10-13T14:14:37+00:00",
    "journal_ref": null,
    "doi": null
  },
  {
    "entry_id": "http://arxiv.org/abs/2510.11418v1",
    "title": "Forward-Forward Autoencoder Architectures for Energy-Efficient Wireless Communications",
    "authors": [
      "Daniel Seifert",
      "Onur Günlü",
      "Rafael F. Schaefer"
    ],
    "summary": "The application of deep learning to the area of communications systems has\nbeen a growing field of interest in recent years. Forward-forward (FF) learning\nis an efficient alternative to the backpropagation (BP) algorithm, which is the\ntypically used training procedure for neural networks. Among its several\nadvantages, FF learning does not require the communication channel to be\ndifferentiable and does not rely on the global availability of partial\nderivatives, allowing for an energy-efficient implementation. In this work, we\ndesign end-to-end learned autoencoders using the FF algorithm and numerically\nevaluate their performance for the additive white Gaussian noise and Rayleigh\nblock fading channels. We demonstrate their competitiveness with BP-trained\nsystems in the case of joint coding and modulation, and in a scenario where a\nfixed, non-differentiable modulation stage is applied. Moreover, we provide\nfurther insights into the design principles of the FF network, its training\nconvergence behavior, and significant memory and processing time savings\ncompared to BP-based approaches.",
    "primary_category": "cs.IT",
    "categories": [
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "published": "2025-10-13T13:54:50+00:00",
    "updated": "2025-10-13T13:54:50+00:00",
    "journal_ref": null,
    "doi": null
  },
  {
    "entry_id": "http://arxiv.org/abs/2510.11409v1",
    "title": "Leveraging LLMs for Semi-Automatic Corpus Filtration in Systematic Literature Reviews",
    "authors": [
      "Lucas Joos",
      "Daniel A. Keim",
      "Maximilian T. Fischer"
    ],
    "summary": "The creation of systematic literature reviews (SLR) is critical for analyzing\nthe landscape of a research field and guiding future research directions.\nHowever, retrieving and filtering the literature corpus for an SLR is highly\ntime-consuming and requires extensive manual effort, as keyword-based searches\nin digital libraries often return numerous irrelevant publications. In this\nwork, we propose a pipeline leveraging multiple large language models (LLMs),\nclassifying papers based on descriptive prompts and deciding jointly using a\nconsensus scheme. The entire process is human-supervised and interactively\ncontrolled via our open-source visual analytics web interface, LLMSurver, which\nenables real-time inspection and modification of model outputs. We evaluate our\napproach using ground-truth data from a recent SLR comprising over 8,000\ncandidate papers, benchmarking both open and commercial state-of-the-art LLMs\nfrom mid-2024 and fall 2025. Results demonstrate that our pipeline\nsignificantly reduces manual effort while achieving lower error rates than\nsingle human annotators. Furthermore, modern open-source models prove\nsufficient for this task, making the method accessible and cost-effective.\nOverall, our work demonstrates how responsible human-AI collaboration can\naccelerate and enhance systematic literature reviews within academic workflows.",
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.DL",
      "cs.HC"
    ],
    "published": "2025-10-13T13:48:29+00:00",
    "updated": "2025-10-13T13:48:29+00:00",
    "journal_ref": null,
    "doi": null
  }
]