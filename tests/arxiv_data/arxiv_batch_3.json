[
  {
    "entry_id": "http://arxiv.org/abs/2510.11579v1",
    "title": "MS-Mix: Unveiling the Power of Mixup for Multimodal Sentiment Analysis",
    "authors": [
      "Hongyu Zhu",
      "Lin Chen",
      "Mounim A. El-Yacoubi",
      "Mingsheng Shang"
    ],
    "summary": "Multimodal Sentiment Analysis (MSA) aims to identify and interpret human\nemotions by integrating information from heterogeneous data sources such as\ntext, video, and audio. While deep learning models have advanced in network\narchitecture design, they remain heavily limited by scarce multimodal annotated\ndata. Although Mixup-based augmentation improves generalization in unimodal\ntasks, its direct application to MSA introduces critical challenges: random\nmixing often amplifies label ambiguity and semantic inconsistency due to the\nlack of emotion-aware mixing mechanisms. To overcome these issues, we propose\nMS-Mix, an adaptive, emotion-sensitive augmentation framework that\nautomatically optimizes sample mixing in multimodal settings. The key\ncomponents of MS-Mix include: (1) a Sentiment-Aware Sample Selection (SASS)\nstrategy that effectively prevents semantic confusion caused by mixing samples\nwith contradictory emotions. (2) a Sentiment Intensity Guided (SIG) module\nusing multi-head self-attention to compute modality-specific mixing ratios\ndynamically based on their respective emotional intensities. (3) a Sentiment\nAlignment Loss (SAL) that aligns the prediction distributions across\nmodalities, and incorporates the Kullback-Leibler-based loss as an additional\nregularization term to train the emotion intensity predictor and the backbone\nnetwork jointly. Extensive experiments on three benchmark datasets with six\nstate-of-the-art backbones confirm that MS-Mix consistently outperforms\nexisting methods, establishing a new standard for robust multimodal sentiment\naugmentation. The source code is available at:\nhttps://github.com/HongyuZhu-s/MS-Mix.",
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-13T16:23:32+00:00",
    "updated": "2025-10-13T16:23:32+00:00",
    "journal_ref": null,
    "doi": null
  },
  {
    "entry_id": "http://arxiv.org/abs/2510.11567v1",
    "title": "A Framework for Low-Effort Training Data Generation for Urban Semantic Segmentation",
    "authors": [
      "Denis Zavadski",
      "Damjan Kalšan",
      "Tim Küchler",
      "Haebom Lee",
      "Stefan Roth",
      "Carsten Rother"
    ],
    "summary": "Synthetic datasets are widely used for training urban scene recognition\nmodels, but even highly realistic renderings show a noticeable gap to real\nimagery. This gap is particularly pronounced when adapting to a specific target\ndomain, such as Cityscapes, where differences in architecture, vegetation,\nobject appearance, and camera characteristics limit downstream performance.\nClosing this gap with more detailed 3D modelling would require expensive asset\nand scene design, defeating the purpose of low-cost labelled data. To address\nthis, we present a new framework that adapts an off-the-shelf diffusion model\nto a target domain using only imperfect pseudo-labels. Once trained, it\ngenerates high-fidelity, target-aligned images from semantic maps of any\nsynthetic dataset, including low-effort sources created in hours rather than\nmonths. The method filters suboptimal generations, rectifies image-label\nmisalignments, and standardises semantics across datasets, transforming weak\nsynthetic data into competitive real-domain training sets. Experiments on five\nsynthetic datasets and two real target datasets show segmentation gains of up\nto +8.0%pt. mIoU over state-of-the-art translation methods, making rapidly\nconstructed synthetic datasets as effective as high-effort, time-intensive\nsynthetic datasets requiring extensive manual design. This work highlights a\nvaluable collaborative paradigm where fast semantic prototyping, combined with\ngenerative models, enables scalable, high-quality training data creation for\nurban scene understanding.",
    "primary_category": "cs.CV",
    "categories": [
      "cs.CV",
      "cs.GR",
      "cs.LG"
    ],
    "published": "2025-10-13T16:12:29+00:00",
    "updated": "2025-10-13T16:12:29+00:00",
    "journal_ref": null,
    "doi": null
  },
  {
    "entry_id": "http://arxiv.org/abs/2510.11561v1",
    "title": "Ontolearn-A Framework for Large-scale OWL Class Expression Learning in Python",
    "authors": [
      "Caglar Demir",
      "Alkid Baci",
      "N'Dah Jean Kouagou",
      "Leonie Nora Sieger",
      "Stefan Heindorf",
      "Simon Bin",
      "Lukas Blübaum",
      "Alexander Bigerl",
      "Axel-Cyrille Ngonga Ngomo"
    ],
    "summary": "In this paper, we present Ontolearn-a framework for learning OWL class\nexpressions over large knowledge graphs. Ontolearn contains efficient\nimplementations of recent stateof-the-art symbolic and neuro-symbolic class\nexpression learners including EvoLearner and DRILL. A learned OWL class\nexpression can be used to classify instances in the knowledge graph.\nFurthermore, Ontolearn integrates a verbalization module based on an LLM to\ntranslate complex OWL class expressions into natural language sentences. By\nmapping OWL class expressions into respective SPARQL queries, Ontolearn can be\neasily used to operate over a remote triplestore. The source code of Ontolearn\nis available at https://github.com/dice-group/Ontolearn.",
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.SC"
    ],
    "published": "2025-10-13T16:04:06+00:00",
    "updated": "2025-10-13T16:04:06+00:00",
    "journal_ref": "Journal of Machine Learning Research 26 (2025) 1-6",
    "doi": null
  },
  {
    "entry_id": "http://arxiv.org/abs/2510.11546v1",
    "title": "Efficient Group Lasso Regularized Rank Regression with Data-Driven Parameter Determination",
    "authors": [
      "Meixia Lin",
      "Meijiao Shi",
      "Yunhai Xiao",
      "Qian Zhang"
    ],
    "summary": "High-dimensional regression often suffers from heavy-tailed noise and\noutliers, which can severely undermine the reliability of least-squares based\nmethods. To improve robustness, we adopt a non-smooth Wilcoxon score based rank\nobjective and incorporate structured group sparsity regularization, a natural\ngeneralization of the lasso, yielding a group lasso regularized rank regression\nmethod. By extending the tuning-free parameter selection scheme originally\ndeveloped for the lasso, we introduce a data-driven, simulation-based tuning\nrule and further establish a finite-sample error bound for the resulting\nestimator. On the computational side, we develop a proximal augmented\nLagrangian method for solving the associated optimization problem, which\neliminates the singularity issues encountered in existing methods, thereby\nenabling efficient semismooth Newton updates for the subproblems. Extensive\nnumerical experiments demonstrate the robustness and effectiveness of our\nproposed estimator against alternatives, and showcase the scalability of the\nalgorithm across both simulated and real-data settings.",
    "primary_category": "stat.ML",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.OC",
      "math.ST",
      "stat.TH"
    ],
    "published": "2025-10-13T15:45:58+00:00",
    "updated": "2025-10-13T15:45:58+00:00",
    "journal_ref": null,
    "doi": null
  },
  {
    "entry_id": "http://arxiv.org/abs/2510.11541v1",
    "title": "Query-Specific GNN: A Comprehensive Graph Representation Learning Method for Retrieval Augmented Generation",
    "authors": [
      "Yuchen Yan",
      "Zhihua Liu",
      "Hao Wang",
      "Weiming Li",
      "Xiaoshuai Hao"
    ],
    "summary": "Retrieval-augmented generation (RAG) has demonstrated its ability to enhance\nLarge Language Models (LLMs) by integrating external knowledge sources.\nHowever, multi-hop questions, which require the identification of multiple\nknowledge targets to form a synthesized answer, raise new challenges for RAG\nsystems. Under the multi-hop settings, existing methods often struggle to fully\nunderstand the questions with complex semantic structures and are susceptible\nto irrelevant noise during the retrieval of multiple information targets. To\naddress these limitations, we propose a novel graph representation learning\nframework for multi-hop question retrieval. We first introduce a\nMulti-information Level Knowledge Graph (Multi-L KG) to model various\ninformation levels for a more comprehensive understanding of multi-hop\nquestions. Based on this, we design a Query-Specific Graph Neural Network\n(QSGNN) for representation learning on the Multi-L KG. QSGNN employs\nintra/inter-level message passing mechanisms, and in each message passing the\ninformation aggregation is guided by the query, which not only facilitates\nmulti-granular information aggregation but also significantly reduces the\nimpact of noise. To enhance its ability to learn robust representations, we\nfurther propose two synthesized data generation strategies for pre-training the\nQSGNN. Extensive experimental results demonstrate the effectiveness of our\nframework in multi-hop scenarios, especially in high-hop questions the\nimprovement can reach 33.8\\%. The code is available at:\nhttps://github.com/Jerry2398/QSGNN.",
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-13T15:41:15+00:00",
    "updated": "2025-10-13T15:41:15+00:00",
    "journal_ref": null,
    "doi": null
  },
  {
    "entry_id": "http://arxiv.org/abs/2510.11507v1",
    "title": "Automatic Music Sample Identification with Multi-Track Contrastive Learning",
    "authors": [
      "Alain Riou",
      "Joan Serrà",
      "Yuki Mitsufuji"
    ],
    "summary": "Sampling, the technique of reusing pieces of existing audio tracks to create\nnew music content, is a very common practice in modern music production. In\nthis paper, we tackle the challenging task of automatic sample identification,\nthat is, detecting such sampled content and retrieving the material from which\nit originates. To do so, we adopt a self-supervised learning approach that\nleverages a multi-track dataset to create positive pairs of artificial mixes,\nand design a novel contrastive learning objective. We show that such method\nsignificantly outperforms previous state-of-the-art baselines, that is robust\nto various genres, and that scales well when increasing the number of noise\nsongs in the reference database. In addition, we extensively analyze the\ncontribution of the different components of our training pipeline and\nhighlight, in particular, the need for high-quality separated stems for this\ntask.",
    "primary_category": "cs.SD",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "published": "2025-10-13T15:17:08+00:00",
    "updated": "2025-10-13T15:17:08+00:00",
    "journal_ref": null,
    "doi": null
  },
  {
    "entry_id": "http://arxiv.org/abs/2510.11505v1",
    "title": "Knowledge-Guided Machine Learning Models to Upscale Evapotranspiration in the U.S. Midwest",
    "authors": [
      "Aleksei Rozanov",
      "Samikshya Subedi",
      "Vasudha Sharma",
      "Bryan C. Runck"
    ],
    "summary": "Evapotranspiration (ET) plays a critical role in the land-atmosphere\ninteractions, yet its accurate quantification across various spatiotemporal\nscales remains a challenge. In situ measurement approaches, like eddy\ncovariance (EC) or weather station-based ET estimation, allow for measuring ET\nat a single location. Agricultural uses of ET require estimates for each field\nover broad areas, making it infeasible to deploy sensing systems at each\nlocation. This study integrates tree-based and knowledge-guided machine\nlearning (ML) techniques with multispectral remote sensing data, griddled\nmeteorology and EC data to upscale ET across the Midwest United States. We\ncompare four tree-based models - Random Forest, CatBoost, XGBoost, LightGBM -\nand a simple feed-forward artificial neural network in combination with\nfeatures engineered using knowledge-guided ML principles. Models were trained\nand tested on EC towers located in the Midwest of the United States using\nk-fold cross validation with k=5 and site-year, biome stratified train-test\nsplit to avoid data leakage. Results show that LightGBM with knowledge-guided\nfeatures outperformed other methods with an R2=0.86, MSE=14.99 W m^-2 and MAE =\n8.82 W m^-2 according to grouped k-fold validation (k=5). Feature importance\nanalysis shows that knowledge-guided features were most important for\npredicting evapotranspiration. Using the best performing model, we provide a\ndata product at 500 m spatial and one-day temporal resolution for gridded ET\nfor the period of 2019-2024. Intercomparison between the new gridded product\nand state-level weather station-based ET estimates show best-in-class\ncorrespondence.",
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-13T15:15:40+00:00",
    "updated": "2025-10-13T15:15:40+00:00",
    "journal_ref": null,
    "doi": null
  },
  {
    "entry_id": "http://arxiv.org/abs/2510.11502v1",
    "title": "Learning to Make MISTAKEs: Modeling Incorrect Student Thinking And Key Errors",
    "authors": [
      "Alexis Ross",
      "Jacob Andreas"
    ],
    "summary": "Research on reasoning in language models (LMs) predominantly focuses on\nimproving the correctness of their outputs. But some important applications\nrequire modeling reasoning patterns that are incorrect. For example, automated\nsystems that can reason about and simulate student errors are useful for\nproviding real-time feedback in the classroom or offline practice for\neducators-in-training. This paper presents a new method, MISTAKE, that (1)\nconstructs high-quality synthetic examples of reasoning errors by leveraging\ncycle consistency between incorrect answers and latent misconceptions; and (2)\nuses the generated data to learn models for student simulation, misconception\nclassification, and answer generation. We evaluate MISTAKE on three educational\ntasks and find that it results in (1) higher accuracy when simulating incorrect\nstudent answers based on specific misconceptions, (2) increased performance\ninferring latent misconceptions from observed incorrect answers, and (3) higher\nalignment with expert-written distractor answers when generating incorrect\nanswers (e.g., for multiple-choice tests).",
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-13T15:10:38+00:00",
    "updated": "2025-10-13T15:10:38+00:00",
    "journal_ref": null,
    "doi": null
  },
  {
    "entry_id": "http://arxiv.org/abs/2510.11501v1",
    "title": "Context-Aware Model-Based Reinforcement Learning for Autonomous Racing",
    "authors": [
      "Emran Yasser Moustafa",
      "Ivana Dusparic"
    ],
    "summary": "Autonomous vehicles have shown promising potential to be a groundbreaking\ntechnology for improving the safety of road users. For these vehicles, as well\nas many other safety-critical robotic technologies, to be deployed in\nreal-world applications, we require algorithms that can generalize well to\nunseen scenarios and data. Model-based reinforcement learning algorithms (MBRL)\nhave demonstrated state-of-the-art performance and data efficiency across a\ndiverse set of domains. However, these algorithms have also shown\nsusceptibility to changes in the environment and its transition dynamics.\n  In this work, we explore the performance and generalization capabilities of\nMBRL algorithms for autonomous driving, specifically in the simulated\nautonomous racing environment, Roboracer (formerly F1Tenth). We frame the\nhead-to-head racing task as a learning problem using contextual Markov decision\nprocesses and parameterize the driving behavior of the adversaries using the\ncontext of the episode, thereby also parameterizing the transition and reward\ndynamics. We benchmark the behavior of MBRL algorithms in this environment and\npropose a novel context-aware extension of the existing literature, cMask. We\ndemonstrate that context-aware MBRL algorithms generalize better to\nout-of-distribution adversary behaviors relative to context-free approaches. We\nalso demonstrate that cMask displays strong generalization capabilities, as\nwell as further performance improvement relative to other context-aware MBRL\napproaches when racing against adversaries with in-distribution behaviors.",
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.RO"
    ],
    "published": "2025-10-13T15:09:09+00:00",
    "updated": "2025-10-13T15:09:09+00:00",
    "journal_ref": null,
    "doi": null
  },
  {
    "entry_id": "http://arxiv.org/abs/2510.11499v1",
    "title": "Offline Reinforcement Learning with Generative Trajectory Policies",
    "authors": [
      "Xinsong Feng",
      "Leshu Tang",
      "Chenan Wang",
      "Haipeng Chen"
    ],
    "summary": "Generative models have emerged as a powerful class of policies for offline\nreinforcement learning (RL) due to their ability to capture complex,\nmulti-modal behaviors. However, existing methods face a stark trade-off: slow,\niterative models like diffusion policies are computationally expensive, while\nfast, single-step models like consistency policies often suffer from degraded\nperformance. In this paper, we demonstrate that it is possible to bridge this\ngap. The key to moving beyond the limitations of individual methods, we argue,\nlies in a unifying perspective that views modern generative models, including\ndiffusion, flow matching, and consistency models, as specific instances of\nlearning a continuous-time generative trajectory governed by an Ordinary\nDifferential Equation (ODE). This principled foundation provides a clearer\ndesign space for generative policies in RL and allows us to propose Generative\nTrajectory Policies (GTPs), a new and more general policy paradigm that learns\nthe entire solution map of the underlying ODE. To make this paradigm practical\nfor offline RL, we further introduce two key theoretically principled\nadaptations. Empirical results demonstrate that GTP achieves state-of-the-art\nperformance on D4RL benchmarks - it significantly outperforms prior generative\npolicies, achieving perfect scores on several notoriously hard AntMaze tasks.",
    "primary_category": "cs.LG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-13T15:06:28+00:00",
    "updated": "2025-10-13T15:06:28+00:00",
    "journal_ref": null,
    "doi": null
  }
]